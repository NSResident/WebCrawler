Requester:
    Implement GET
    Implement POST

Crawling:
    Create map of already traversed links (?)
    Robots.txt crawl (probably add robotsCrawl after initial crawling is done)

Parsing:

BruteForce:
    Find form elements
    Notify user whether a login was succesful 

Questions:
    -Do the keywords have to be in search order
    Robots.txt/subdomain
    -How deep
    -Does it count towards page count 
    -Does it also follow dfs/bfs

